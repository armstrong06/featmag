{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "# make paths above 'notebooks/' visible for local imports.\n",
    "# +----------------------------------------------------------------------------+\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.processing import GatherFeatureDatasets\n",
    "from src.utils import CrossValidation\n",
    "from src.feature_selection import CustomRFECVUpdate\n",
    "from src.feature_selection import IntrinsicFeatureSelection as ifs\n",
    "from src.plotting import plot_pairwise_correlations\n",
    "from src.utils import NumpyEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = GatherFeatureDatasets(is_p=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/uufs/chpc.utah.edu/common/home/koper-group3/alysha/magnitudes/feature_splits'\n",
    "outpath = '/uufs/chpc.utah.edu/common/home/koper-group3/alysha/magnitudes/feature_selection_update/experiment_YUF'\n",
    "all_train_df = pd.read_csv(f'{data_dir}/p.train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YUF\n",
      "X shape: (1676, 45), y shape: (1676,)\n"
     ]
    }
   ],
   "source": [
    "# Use station YUF for experimenting with models because it has 1433 training examples, \n",
    "# which is ~half as much as YNR, so training should go faster. But should still be enough \n",
    "# examples for training good models. It is also one of the stations with a \n",
    "# UUSS correction, so already used for magnitude calculations and amplitudes should be good quality. \n",
    "stat = \"YUF\"\n",
    "station_feature_dict_rel, station_meta_dict_rel, feature_names_rel = proc.process_station_datasets(stat, \n",
    "                                                                                        all_train_df,\n",
    "                                                                                        scaler=False,\n",
    "                                                                                        linear_model=False,\n",
    "                                                                                        source_dist_type='dist') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amp_ratio_1', 'amp_ratio_2', 'amp_ratio_3', 'amp_ratio_4',\n",
       "       'amp_ratio_5', 'amp_ratio_6', 'amp_ratio_7', 'amp_ratio_8',\n",
       "       'amp_ratio_9', 'amp_ratio_10', 'amp_ratio_11', 'amp_ratio_12',\n",
       "       'amp_ratio_13', 'amp_ratio_14', 'amp_ratio_15', 'amp_ratio_16',\n",
       "       'amp_ratio_17', 'amp_ratio_18', 'amp_1', 'amp_2', 'amp_3', 'amp_4',\n",
       "       'amp_5', 'amp_6', 'amp_7', 'amp_8', 'amp_9', 'amp_10', 'amp_11',\n",
       "       'amp_12', 'amp_13', 'amp_14', 'amp_15', 'amp_16', 'amp_17',\n",
       "       'amp_18', 'signal_dominant_frequency', 'signal_dominant_amplitude',\n",
       "       'noise_max_amplitude', 'signal_max_amplitude', 'signal_variance',\n",
       "       'noise_variance', 'source_depth_km',\n",
       "       'source_receiver_distance_logkm',\n",
       "       'source_receiver_back_azimuth_deg'], dtype='<U32')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rel = station_feature_dict_rel['X_train']\n",
    "y_rel = station_meta_dict_rel['y_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use RFECV to select N with different estimator models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Parameters ###\n",
    "cv_random_state=2652124\n",
    "# The scoring method to use in RFECV and GridCV\n",
    "scoring_method = 'r2'\n",
    "# The function used to evaluate the performance on the test model\n",
    "score_func = r2_score\n",
    "# True if a larger score_func value is better\n",
    "larger_score_is_better = True\n",
    "# The number of jobs for RFECV and GridCV to use\n",
    "n_jobs = 10\n",
    "# number of folds for outer CV\n",
    "cv_folds_outer = 10\n",
    "# number of times to repeat outer CV\n",
    "n_outer_repeats = 1\n",
    "# number of folds for inner CV (used for hyperparameter tuning)\n",
    "cv_folds_inner = 5\n",
    "# number of folds for the final hyperparameter grid search\n",
    "cv_folds_hp = 10\n",
    "# Run grid search over all features\n",
    "run_gridsearchcv_all = True\n",
    "\n",
    "### Intrisic feature selection information \n",
    "# Function that takes in X, y, list of np arrays containing \n",
    "# the indices of features to filter, and K features to select\n",
    "if_feat_inds = [np.arange(0, 18), np.arange(18, 36)]\n",
    "if_K = 5\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_seed = 2652129\n",
    "outfile = 'rfecv.relDist.trees.json'\n",
    "\n",
    "models = {\"RF\": RandomForestRegressor(random_state=estimators_seed), \n",
    "         \"GBT\": GradientBoostingRegressor(random_state=estimators_seed)}\n",
    "scaler = False\n",
    "\n",
    "param_grids = {\"RF\": {\"m__max_features\": [1, 4, 6],\n",
    "                                \"m__n_estimators\": [100, 500, 1000]},\n",
    "                        \"GBT\": {'m__n_estimators': [100, 500, 1000], \n",
    "                                'm__max_depth': [1, 3, 5]}\n",
    "                        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 500} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=500, random_state=2652129)\n",
      "Fold 0: N=11, test_score=0.902\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 500} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=500, random_state=2652129)\n",
      "Fold 1: N=12, test_score=0.894\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 1000} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=1000, random_state=2652129)\n",
      "Fold 2: N=10, test_score=0.893\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 1000} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=1000, random_state=2652129)\n",
      "Fold 3: N=9, test_score=0.899\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 1000} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=1000, random_state=2652129)\n",
      "Fold 4: N=8, test_score=0.909\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 1000} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=1000, random_state=2652129)\n",
      "Fold 5: N=15, test_score=0.903\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 1000} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=1000, random_state=2652129)\n",
      "Fold 6: N=13, test_score=0.881\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 1000} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=1000, random_state=2652129)\n",
      "Fold 7: N=14, test_score=0.907\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 1000} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=1000, random_state=2652129)\n",
      "Fold 8: N=8, test_score=0.902\n",
      "reducing features to 19\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 500} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=500, random_state=2652129)\n",
      "Fold 9: N=8, test_score=0.876\n",
      "total time: 5004.49 s\n",
      "Selected number of features: 12 (avg. score of 0.89); 1 STE: N=5 (avg. 0.86)\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 1, 'm__n_estimators': 1000} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=1, n_estimators=1000, random_state=2652129)\n",
      "Fold 0: N=18, test_score=0.914\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 5, 'm__n_estimators': 500} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=5, n_estimators=500, random_state=2652129)\n",
      "Fold 1: N=14, test_score=0.904\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 1, 'm__n_estimators': 1000} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=1, n_estimators=1000, random_state=2652129)\n",
      "Fold 2: N=10, test_score=0.922\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 3, 'm__n_estimators': 500} for the estimator model\n",
      "GradientBoostingRegressor(n_estimators=500, random_state=2652129)\n",
      "Fold 3: N=7, test_score=0.903\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 1, 'm__n_estimators': 1000} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=1, n_estimators=1000, random_state=2652129)\n",
      "Fold 4: N=10, test_score=0.911\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 5, 'm__n_estimators': 1000} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=5, n_estimators=1000, random_state=2652129)\n",
      "Fold 5: N=11, test_score=0.916\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 1, 'm__n_estimators': 1000} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=1, n_estimators=1000, random_state=2652129)\n",
      "Fold 6: N=16, test_score=0.880\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 1, 'm__n_estimators': 1000} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=1, n_estimators=1000, random_state=2652129)\n",
      "Fold 7: N=9, test_score=0.909\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 3, 'm__n_estimators': 500} for the estimator model\n",
      "GradientBoostingRegressor(n_estimators=500, random_state=2652129)\n",
      "Fold 8: N=12, test_score=0.913\n",
      "reducing features to 19\n",
      "Using {'m__max_depth': 5, 'm__n_estimators': 100} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=5, random_state=2652129)\n",
      "Fold 9: N=9, test_score=0.885\n",
      "total time: 3609.89 s\n",
      "Selected number of features: 18 (avg. score of 0.90); 1 STE: N=6 (avg. 0.88)\n"
     ]
    }
   ],
   "source": [
    "estimator_rfe_results_tuned = {}\n",
    "for key in models.keys():\n",
    "  model = models[key]\n",
    "  params = param_grids[key]\n",
    "  mname = type(model).__name__\n",
    "  feat_selection_results = CustomRFECVUpdate.do_rfecv(X_rel,\n",
    "                                                y_rel,\n",
    "                                              model,\n",
    "                                              model,\n",
    "                                              params,\n",
    "                                              estimator_params_grid=params,\n",
    "                                              estimator_scaler=scaler,\n",
    "                                              predictor_scaler=scaler,\n",
    "                                              score_func=score_func,\n",
    "                                              scoring_method=scoring_method,\n",
    "                                              n_jobs=n_jobs,\n",
    "                                              cv_folds_outer=cv_folds_outer,\n",
    "                                              cv_folds_inner=cv_folds_inner,\n",
    "                                              n_outer_repeats=n_outer_repeats,\n",
    "                                              cv_random_state=cv_random_state,\n",
    "                                              larger_score_is_better=larger_score_is_better,\n",
    "                                              intrinsic_filter_func=ifs.MI_filter_func,\n",
    "                                              feature_inds_to_filter=if_feat_inds,\n",
    "                                              intrinsic_filter_K=if_K\n",
    "                                              )\n",
    "  estimator_rfe_results_tuned[mname] = feat_selection_results\n",
    "\n",
    "with open(os.path.join(outpath, outfile), 'w') as fp:\n",
    "    json.dump(estimator_rfe_results_tuned, fp, indent=4, cls=NumpyEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model using the selected number of features on the full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outpath, outfile), 'r') as fp: \n",
    "       estimator_rfe_results_tuned = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amp_ratio_7' 'amp_ratio_6' 'amp_ratio_4' 'amp_ratio_5' 'amp_ratio_2'] ['amp_1' 'amp_2' 'amp_4' 'amp_3' 'amp_7']\n",
      "(1676, 19)\n"
     ]
    }
   ],
   "source": [
    "# Filter the entire training dataset using MI and the same parameters used in CV\n",
    "mi_selected_features, mi_filtered_feature_inds = ifs.MI_filter_func(X_rel, \n",
    "                                                                    y_rel, \n",
    "                                                                    if_feat_inds, \n",
    "                                                                    if_K)\n",
    "print(feature_names_rel[mi_selected_features[0]], feature_names_rel[mi_selected_features[1]])\n",
    "X_mi = X_rel[:, mi_filtered_feature_inds]\n",
    "print(X_mi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amp_ratio_2', 'amp_ratio_4', 'amp_ratio_5', 'amp_ratio_6',\n",
       "       'amp_ratio_7', 'amp_1', 'amp_2', 'amp_3', 'amp_4', 'amp_7',\n",
       "       'signal_dominant_frequency', 'signal_dominant_amplitude',\n",
       "       'noise_max_amplitude', 'signal_max_amplitude', 'signal_variance',\n",
       "       'noise_variance', 'source_depth_km',\n",
       "       'source_receiver_distance_logkm',\n",
       "       'source_receiver_back_azimuth_deg'], dtype='<U32')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_rel[mi_filtered_feature_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor Estimator Scaler: False\n",
      "Using {'m__max_features': 6, 'm__n_estimators': 1000} for the estimator model\n",
      "RandomForestRegressor(max_features=6, n_estimators=1000, random_state=2652129)\n",
      "{'best': 12, 'oste': 5}\n",
      "[17  5  6  7 16  8 14 18 10  9 13  0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12: CV Mean: 0.89, CV STD: 0.01\n",
      "[17  5  6  7 16]\n",
      "5: CV Mean: 0.86, CV STD: 0.02\n",
      "GradientBoostingRegressor Estimator Scaler: False\n",
      "Using {'m__max_depth': 1, 'm__n_estimators': 1000} for the estimator model\n",
      "GradientBoostingRegressor(max_depth=1, n_estimators=1000, random_state=2652129)\n",
      "{'best': 18, 'oste': 6}\n",
      "[17  5  6 16  1  8  4 18  0  9  3  7 14 15 10 11 12  2]\n",
      "18: CV Mean: 0.91, CV STD: 0.01\n",
      "[17  5  6 16  1  8]\n",
      "6: CV Mean: 0.88, CV STD: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Set up SVR hyperparameter grid search\n",
    "# If this isn't reran when the feature selection is reran then\n",
    "# the results may be slightly different\n",
    "\n",
    "full_estimator_rfe_results_rel_tuned = {}\n",
    "for key in models.keys():\n",
    "    model = models[key]\n",
    "    params = param_grids[key]\n",
    "    mname = type(model).__name__\n",
    "    print(mname, 'Estimator Scaler:', scaler)\n",
    "\n",
    "    predictor_model = clone(model)\n",
    "    estimator_model = clone(model)\n",
    "    hp_grid_search, hp_cv = CrossValidation.setup_cv(predictor_model, \n",
    "                                                    params, \n",
    "                                                    model_scaler=scaler, \n",
    "                                                    scoring_method=scoring_method, \n",
    "                                                    n_jobs=n_jobs, \n",
    "                                                    cv_folds=cv_folds_outer, \n",
    "                                                    cv_random_state=cv_random_state, \n",
    "                                                    refit_model=False)\n",
    "\n",
    "    rfecv_results_dict = estimator_rfe_results_tuned[mname]\n",
    "\n",
    "    estimator_grid_search, estimator_cv = CrossValidation.setup_cv(estimator_model, \n",
    "                                                                params, \n",
    "                                                                model_scaler=scaler, \n",
    "                                                                scoring_method=scoring_method, \n",
    "                                                                n_jobs=n_jobs, \n",
    "                                                                cv_folds=cv_folds_inner, \n",
    "                                                                cv_random_state=cv_random_state, \n",
    "                                                                refit_model=False)\n",
    "    \n",
    "    N_results = CustomRFECVUpdate.get_final_N_features_estimator_tuning(X_mi,\n",
    "                                                                  y_rel,\n",
    "                                                                  rfecv_results_dict,\n",
    "                                                                  estimator_model,\n",
    "                                                                  scaler,\n",
    "                                                                  estimator_grid_search,\n",
    "                                                                  hp_grid_search,\n",
    "                                                                  filtered_feat_inds=mi_filtered_feature_inds\n",
    "                                                                  )\n",
    "    full_estimator_rfe_results_rel_tuned[mname] = N_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outpath, 'rfe.full.relDist.trees.json'), 'w') as fp:\n",
    "    json.dump(full_estimator_rfe_results_rel_tuned, fp, indent=4, cls=NumpyEncoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "featmags",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
